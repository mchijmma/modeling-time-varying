## A general-purpose deep learning approach to model time-varying audio effects

Audio examples for the [paper](https://link.for.the.paper):

[Martínez Ramírez M. A.](http://m-marco.com), Benetos, E. and Reiss J. D., “A general-purpose deep learning approach to model time-varying audio effects” submitted to the 22nd International Conference on Digital Audio Effects (DAFx-19), Birmingham, UK, September 2019. 

### chorus




<div id="contentBox" style="margin:0px auto; width:150%">
<div id="column1" style="float:left; margin:0; width:36.5%;">
- input <br />

<audio controls="controls">
    <source src="audio/chorus/1-chorus_input.ogg" type="audio/ogg" />
</audio>
</div>

<div id="column2" style="float:left; margin:0;width:36.5%;">
- target <br />

    <audio controls="controls" >
    <source src="audio/chorus/1-chorus_input.ogg" type="audio/ogg" />
</audio>
</div>

<div id="column3" style="float:left; margin:0;width:27%">
- output <br />

    <audio controls="controls">
    <source src="audio/chorus/1-chorus_input.ogg" type="audio/ogg" />
</audio>
</div>
</div>










### Citation


<font size="1">
@inproceedings{martinez2019general,<br />
title={A general\-purpose deep learning approach to model time-varying audio effects},<br />
author={Mart\'{i}nez Ram\'{i}rez, Marco A., Benetos, Emmanouil and Reiss, Joshua D.},<br />
booktitle={ submitted to the 22nd International Conference on Digital Audio Effects (DAFx-19)},<br />
Month = {September},<br />
year = {2019},<br />
location = {Birmingham, UK}<br />
}<br />



